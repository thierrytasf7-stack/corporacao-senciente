/**
 * Teste de IntegraÃ§Ã£o Ollama
 * 
 * Verifica se Ollama estÃ¡ configurado e funcionando
 */

import { checkOllamaAvailable, callLLM } from './utils/llm_client.js';
import { default as llmClient } from './utils/llm_client.js';
import { config } from 'dotenv';
import fs from 'fs';

config({ path: fs.existsSync('.env') ? '.env' : 'env.local' });

async function testOllama() {
    console.log('\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
    console.log('   TESTE DE INTEGRAÃ‡ÃƒO OLLAMA');
    console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');

    // 1. Verificar disponibilidade
    console.log('1ï¸âƒ£ Verificando se Ollama estÃ¡ disponÃ­vel...');
    const available = await checkOllamaAvailable();
    
    if (!available) {
        console.log('âŒ Ollama nÃ£o estÃ¡ disponÃ­vel');
        console.log('\nğŸ“ Para instalar:');
        console.log('   1. Baixe: https://ollama.com/download');
        console.log('   2. Instale e execute');
        console.log('   3. Baixe um modelo: ollama pull llama3.2');
        console.log('   4. Configure OLLAMA_ENABLED=true no env.local\n');
        return;
    }

    console.log('âœ… Ollama estÃ¡ disponÃ­vel\n');

    // 2. Teste direto
    console.log('2ï¸âƒ£ Testando chamada direta ao Ollama...');
    try {
        const result = await llmClient.callOllama(
            'Responda apenas: "Ollama estÃ¡ funcionando!"',
            '',
            0.7
        );
        
        if (result) {
            console.log('âœ… Chamada direta funcionou');
            console.log(`   Resposta: ${result.substring(0, 100)}...\n`);
        } else {
            console.log('âŒ Chamada direta retornou null\n');
        }
    } catch (error) {
        console.log(`âŒ Erro na chamada direta: ${error.message}\n`);
    }

    // 3. Teste com callLLM (treinamento)
    console.log('3ï¸âƒ£ Testando callLLM com isTraining=true...');
    try {
        const result = await callLLM(
            'Gere um exemplo de pergunta e resposta sobre copywriting.',
            'VocÃª Ã© um especialista em copywriting.',
            0.7,
            { isTraining: true }
        );
        
        if (result) {
            console.log('âœ… callLLM com treinamento funcionou');
            console.log(`   Resposta: ${result.substring(0, 150)}...\n`);
        } else {
            console.log('âŒ callLLM retornou null\n');
        }
    } catch (error) {
        console.log(`âŒ Erro no callLLM: ${error.message}\n`);
    }

    // 4. Resumo
    console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
    console.log('   RESUMO');
    console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');
    console.log('âœ… Ollama estÃ¡ configurado e funcionando!');
    console.log('âœ… O sistema usarÃ¡ Ollama automaticamente para treinamento');
    console.log('âœ… Rate limits do Grok nÃ£o serÃ£o mais um problema\n');
}

testOllama().catch(error => {
    console.error('âŒ Erro no teste:', error);
    process.exit(1);
});

