---
task: Benchmark Agent
responsavel: "@benchmark-analyst"
responsavel_type: agent
atomic_layer: task
elicit: false
Entrada: |
  - agent_path: Caminho para o arquivo .md do agente
  - model: Modelo que roda o agente (default: opus)
Saida: |
  - token_analysis: Contagem de tokens do agente (system prompt total)
  - fixed_cost: Custo fixo por ativaÃ§Ã£o
  - waste_map: Mapa de desperdÃ­cio identificado
  - optimization_suggestions: Lista de otimizaÃ§Ãµes com impacto estimado
  - pareto_summary: Top 20% de mudanÃ§as que reduzem 80% do custo
Checklist:
  - "[ ] Ler arquivo do agente completo"
  - "[ ] Estimar token count do system prompt"
  - "[ ] Calcular custo fixo por ativaÃ§Ã£o"
  - "[ ] Identificar redundÃ¢ncias no prompt"
  - "[ ] Identificar contexto nÃ£o utilizado"
  - "[ ] Identificar over-engineering"
  - "[ ] Gerar mapa de desperdÃ­cio"
  - "[ ] Calcular impacto de cada otimizaÃ§Ã£o"
  - "[ ] Ranquear por Pareto (maior impacto primeiro)"
---

# *benchmark-agent

LÃª um agente, calcula custo fixo, identifica desperdÃ­cio e sugere otimizaÃ§Ãµes Pareto.

## Flow

```
1. Ler arquivo do agente
   â”œâ”€â”€ Extrair YAML block (configuraÃ§Ã£o)
   â”œâ”€â”€ Extrair texto livre (instruÃ§Ãµes adicionais)
   â””â”€â”€ Extrair Quick Commands section

2. AnÃ¡lise de tokens
   â”œâ”€â”€ Estimar tokens totais do arquivo (~4 chars = 1 token)
   â”œâ”€â”€ Separar: YAML config vs instruÃ§Ãµes vs commands
   â””â”€â”€ Calcular custo fixo (tokens Ã— preÃ§o input do modelo)

3. DetecÃ§Ã£o de desperdÃ­cio
   â”œâ”€â”€ InstruÃ§Ãµes repetidas (duplicatas ou parÃ¡frases)
   â”œâ”€â”€ Exemplos excessivos (1-2 bastam na maioria dos casos)
   â”œâ”€â”€ VocabulÃ¡rio/vocabulary lists longas (tokens baixo valor)
   â”œâ”€â”€ SeÃ§Ãµes que poderiam ser lazy-loaded (guide, collaboration)
   â”œâ”€â”€ Greeting levels nÃ£o usados (3 levels vs 1 necessÃ¡rio)
   â”œâ”€â”€ Metadata que nÃ£o afeta comportamento
   â””â”€â”€ Over-specification (instruÃ§Ãµes Ã³bvias para o modelo)

4. AnÃ¡lise de qualidade
   â”œâ”€â”€ InstruÃ§Ãµes core estÃ£o claras e sem ambiguidade?
   â”œâ”€â”€ Commands estÃ£o bem mapeados a tasks?
   â”œâ”€â”€ Persona agrega valor ou Ã© overhead?
   â””â”€â”€ Core principles sÃ£o actionable?

5. Gerar recomendaÃ§Ãµes Pareto
   â”œâ”€â”€ Ranquear otimizaÃ§Ãµes por (tokens_saved Ã— facilidade)
   â”œâ”€â”€ Top 20% que cortam 80% do desperdÃ­cio
   â””â”€â”€ Estimar economia em USD/mÃªs
```

## Output Format

```
ğŸ“Š Benchmark Agent: {agent_name} ({agent_id})
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“ Tamanho: ~{total_tokens} tokens ({total_chars} chars)
  YAML config:  ~{yaml_tokens} tokens ({yaml_pct}%)
  InstruÃ§Ãµes:   ~{text_tokens} tokens ({text_pct}%)
  Commands:     ~{cmd_tokens} tokens ({cmd_pct}%)

ğŸ’° Custo fixo por ativaÃ§Ã£o ({model}):
  Input: ${fixed_cost} (system prompt)
  Com cache: ${cached_cost} ({savings}% economia)

ğŸ” DesperdÃ­cio identificado:
{waste_items}

ğŸ¯ Top OtimizaÃ§Ãµes (Pareto 80/20):
{optimization_list}

ğŸ’° Economia estimada: ~{tokens_saved} tokens/ativaÃ§Ã£o = ${monthly_savings}/mÃªs
```

## Waste Categories

| Categoria | Impacto | Exemplo |
|-----------|---------|---------|
| RedundÃ¢ncia | Alto | Mesma instruÃ§Ã£o repetida 2-3x |
| Over-specification | MÃ©dio | "Sempre use TypeScript" (modelo jÃ¡ sabe do contexto) |
| Exemplos excessivos | MÃ©dio | 5 exemplos onde 2 bastam |
| Metadata decorativa | Baixo | Zodiac, archetype (nÃ£o afeta output) |
| Greeting verboso | Baixo | Greeting de 20 linhas vs 5 |
| Vocabulary lists | Baixo | Lista de palavras raramente usadas |
