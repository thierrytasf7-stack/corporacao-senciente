---
task: Benchmark Report
responsavel: "@benchmark-analyst"
responsavel_type: agent
atomic_layer: task
elicit: true
Entrada: |
  - scope: "all" (todas as squads) ou squad especÃ­fica
Saida: |
  - report: RelatÃ³rio completo de benchmark em markdown
Checklist:
  - "[ ] Definir escopo (all ou squad especÃ­fica)"
  - "[ ] Listar todos os agentes no escopo"
  - "[ ] Calcular custo fixo de cada agente"
  - "[ ] Identificar top consumers (agentes mais caros)"
  - "[ ] Gerar recomendaÃ§Ãµes gerais"
  - "[ ] Formatar relatÃ³rio"
---

# *report

Gera relatÃ³rio completo de benchmark com mÃ©tricas de custo e qualidade.

## Flow

```
1. Definir escopo
   â”œâ”€â”€ Se "all" â†’ listar squads/ + .aios-core/development/agents/
   â””â”€â”€ Se squad especÃ­fica â†’ listar agents/ da squad

2. Para cada agente:
   â”œâ”€â”€ Contar tokens do arquivo (chars/4)
   â”œâ”€â”€ Calcular custo fixo por ativaÃ§Ã£o (Opus pricing)
   â””â”€â”€ Classificar: small (<2K tokens), medium (2-5K), large (5-10K), xlarge (>10K)

3. Agregar
   â”œâ”€â”€ Total tokens de system prompts
   â”œâ”€â”€ Total custo fixo por ativaÃ§Ã£o de todos
   â”œâ”€â”€ Ranking por tamanho
   â””â”€â”€ Identificar outliers

4. Gerar relatÃ³rio markdown
```

## Output Format

```
# ðŸ“Š LLM Benchmark Report
Generated: {date}
Scope: {scope}

## Overview
- Agentes analisados: {count}
- Total tokens (system prompts): ~{total_tokens}
- Custo fixo total (1 ativaÃ§Ã£o de cada): ${total_cost}

## Ranking por Custo (maior primeiro)

| # | Agente | Tokens | Custo/ativ | ClassificaÃ§Ã£o |
|---|--------|--------|-----------|---------------|
| 1 | {name} | {tokens} | ${cost} | {class} |
...

## DistribuiÃ§Ã£o
- Small (<2K): {small_count} agentes
- Medium (2-5K): {medium_count} agentes
- Large (5-10K): {large_count} agentes
- XLarge (>10K): {xlarge_count} agentes

## Top 5 RecomendaÃ§Ãµes (Pareto)
1. {rec_1}
2. {rec_2}
...

---
ðŸ“Š Report by Metric (Benchmark Analyst)
```
